#!/usr/bin/env python3
"""
Knowledge Agent API Server
ä½¿ç”¨ FastAPI ä¸º Knowledge Agent æä¾› HTTP API æ¥å£
"""

import asyncio
import json
import logging
import os
import traceback
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import uvicorn
from fastapi import FastAPI, HTTPException, UploadFile, File, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥çŸ¥è¯†åº“ Agent ç»„ä»¶
try:
    from agents.orchestrator import KnowledgeOrchestrator
    from agents.content_parser import ContentParser
    from agents.structure_builder import StructureBuilder
    from agents.link_discoverer import LinkDiscoverer
    from utils.vector_db import LocalVectorDB
    from utils.link_manager import LinkManager
    from utils.progress_websocket import ProgressWebSocketServer
    from utils.file_watcher import create_file_watcher
    from utils.link_renderer import ConceptGraphGenerator
    from config import Settings
    from simple_processor import SimpleKnowledgeProcessor
    FULL_MODE = True
except ImportError as e:
    print(f"è­¦å‘Šï¼šæ— æ³•å¯¼å…¥å®Œæ•´çš„Agentç»„ä»¶: {e}")
    print("ä½¿ç”¨ç®€åŒ–æ¨¡å¼è¿è¡Œ...")
    FULL_MODE = False

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="Knowledge Agent API",
    description="æ™ºèƒ½çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
orchestrator = None
vector_db = None
link_manager = None
file_watcher = None
simple_processor = None

# ç®€åŒ–çš„WebSocketè¿æ¥ç®¡ç†
active_websocket_connections = set()

# Pydantic æ¨¡å‹å®šä¹‰
class ProcessingOptions(BaseModel):
    strategy: str = Field(default="standard", description="å¤„ç†ç­–ç•¥")
    enableLinking: bool = Field(default=True, description="å¯ç”¨é“¾æ¥å‘ç°")
    generateSummary: bool = Field(default=True, description="ç”Ÿæˆæ‘˜è¦")
    extractConcepts: bool = Field(default=True, description="æå–æ¦‚å¿µ")
    enable_vector_db: bool = Field(default=True, description="å¯ç”¨å‘é‡æ•°æ®åº“")
    force_structure: bool = Field(default=False, description="å¼ºåˆ¶ç»“æ„åŒ–")

class ProcessingRequest(BaseModel):
    content: str = Field(..., description="è¦å¤„ç†çš„å†…å®¹")
    type: str = Field(default="text", description="å†…å®¹ç±»å‹")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="å…ƒæ•°æ®")
    options: ProcessingOptions = Field(default_factory=ProcessingOptions, description="å¤„ç†é€‰é¡¹")

class ProcessingResponse(BaseModel):
    success: bool
    result: Optional[Dict[str, Any]] = None
    output_file: Optional[str] = None
    doc_id: Optional[str] = None
    statistics: Optional[Dict[str, Any]] = None
    errors: List[str] = Field(default_factory=list)
    message: Optional[str] = None

class ConceptSearchRequest(BaseModel):
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢")
    limit: int = Field(default=10, description="è¿”å›ç»“æœæ•°é‡")
    threshold: float = Field(default=0.6, description="ç›¸ä¼¼åº¦é˜ˆå€¼")

class ConceptSearchResponse(BaseModel):
    concepts: List[Dict[str, Any]]
    total: int
    query: str

class DocumentSearchRequest(BaseModel):
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢")
    limit: int = Field(default=10, description="è¿”å›ç»“æœæ•°é‡")
    threshold: float = Field(default=0.6, description="ç›¸ä¼¼åº¦é˜ˆå€¼")

class DocumentSearchResponse(BaseModel):
    documents: List[Dict[str, Any]]
    total: int
    query: str

class LinkDiscoveryRequest(BaseModel):
    doc_id: str = Field(..., description="æ–‡æ¡£ID")
    threshold: float = Field(default=0.7, description="é“¾æ¥å‘ç°é˜ˆå€¼")

class LinkDiscoveryResponse(BaseModel):
    links: List[Dict[str, Any]]
    total: int
    doc_id: str

class StatsResponse(BaseModel):
    documents: int
    concepts: int
    links: int
    last_updated: str

class ConceptGraphRequest(BaseModel):
    max_concepts: int = Field(default=100, description="æœ€å¤§æ¦‚å¿µæ•°é‡", ge=1, le=500)
    include_documents: bool = Field(default=False, description="æ˜¯å¦åŒ…å«æ–‡æ¡£èŠ‚ç‚¹")

class ConceptGraphResponse(BaseModel):
    nodes: List[Dict[str, Any]]
    links: List[Dict[str, Any]]
    total_concepts: int
    total_links: int

# ç®€åŒ–çš„è¿›åº¦å¹¿æ’­å‡½æ•°
async def broadcast_progress(progress_data: Dict[str, Any]):
    """å‘æ‰€æœ‰WebSocketè¿æ¥å¹¿æ’­è¿›åº¦æ›´æ–°"""
    global active_websocket_connections
    
    if not active_websocket_connections:
        logger.info("æ²¡æœ‰æ´»è·ƒçš„WebSocketè¿æ¥ï¼Œè·³è¿‡å¹¿æ’­")
        return
    
    message = {
        "type": "progress_update",
        "data": progress_data,
        "timestamp": time.time()
    }
    
    logger.info(f"ğŸ“¡ å¹¿æ’­è¿›åº¦æ›´æ–°ç»™ {len(active_websocket_connections)} ä¸ªå®¢æˆ·ç«¯: {progress_data.get('current_step', 'unknown')}")
    
    # å¹¶å‘å‘é€ç»™æ‰€æœ‰å®¢æˆ·ç«¯
    disconnected_connections = set()
    for websocket in active_websocket_connections.copy():
        try:
            await websocket.send_text(json.dumps(message, ensure_ascii=False))
            logger.info(f"âœ… æˆåŠŸå‘é€æ¶ˆæ¯åˆ°WebSocket")
        except Exception as e:
            logger.error(f"âŒ å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {e}")
            disconnected_connections.add(websocket)
    
    # æ¸…ç†æ–­å¼€çš„è¿æ¥
    active_websocket_connections -= disconnected_connections
    logger.info(f"ğŸ“Š WebSocketå¹¿æ’­å®Œæˆï¼Œå‰©ä½™è¿æ¥: {len(active_websocket_connections)}")

# ç®€åŒ–çš„è¿›åº¦å›è°ƒç±»
class SimpleProgressCallback:
    """ç®€åŒ–çš„è¿›åº¦å›è°ƒ"""
    
    def __call__(self, progress):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        try:
            logger.info(f"ğŸ¯ SimpleProgressCallbackè¢«è°ƒç”¨ï¼")
            progress_data = progress.to_dict()
            
            # è®°å½•è¿›åº¦æ•°æ®ç”¨äºè°ƒè¯•
            logger.info(f"ğŸ“Š [{progress.task_id[:8]}] å‘é€è¿›åº¦æ›´æ–°: {progress.current_step} "
                      f"({progress.completed_steps}/{progress.total_steps}) - å®¢æˆ·ç«¯æ•°é‡: {len(active_websocket_connections)}")
            logger.info(f"ğŸ“Š è¿›åº¦æ•°æ®: {progress_data}")
            
            # åŒæ­¥å¹¿æ’­è¿›åº¦ - ä½¿ç”¨asyncio.create_taskåœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
            try:
                loop = asyncio.get_event_loop()
                logger.info(f"ğŸ”„ è·å–äº‹ä»¶å¾ªç¯æˆåŠŸï¼Œæ­£åœ¨è¿è¡Œ: {loop.is_running()}")
                if loop.is_running():
                    task = asyncio.create_task(broadcast_progress(progress_data))
                    logger.info(f"ğŸ“¤ åˆ›å»ºå¹¿æ’­ä»»åŠ¡: {task}")
                else:
                    logger.info(f"ğŸ“¤ äº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œå¹¿æ’­")
                    loop.run_until_complete(broadcast_progress(progress_data))
            except RuntimeError as e:
                logger.warning(f"âš ï¸ äº‹ä»¶å¾ªç¯å¼‚å¸¸: {e}ï¼Œå°è¯•åˆ›å»ºæ–°çš„")
                # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œå°è¯•åˆ›å»ºæ–°çš„
                asyncio.run(broadcast_progress(progress_data))
            
            # è®°å½•å…³é”®è¿›åº¦ç‚¹
            if progress.stage.value in ["analyzing", "generating_workers", "completed"]:
                logger.info(f"ğŸ¯ [{progress.task_id[:8]}] {progress.current_step} "
                          f"({progress.completed_steps}/{progress.total_steps})")
            
        except Exception as e:
            logger.error(f"âŒ å¹¿æ’­è¿›åº¦å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

# å¯åŠ¨æ—¶åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–ç»„ä»¶"""
    global orchestrator, vector_db, link_manager, file_watcher, simple_processor
    
    logger.info("æ­£åœ¨åˆå§‹åŒ– Knowledge Agent API æœåŠ¡å™¨...")
    
    if not FULL_MODE:
        logger.warning("è¿è¡Œåœ¨ç®€åŒ–æ¨¡å¼ä¸‹ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        return
    
    try:
        # åˆå§‹åŒ–é…ç½®
        settings = Settings()
        
        # åˆå§‹åŒ–ç®€åŒ–å¤„ç†å™¨ - æ–°çš„ä¸»è¦å¤„ç†å™¨
        simple_processor = SimpleKnowledgeProcessor(broadcast_progress)
        logger.info("ç®€åŒ–çŸ¥è¯†å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        vector_db = LocalVectorDB()
        logger.info("å‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–é“¾æ¥ç®¡ç†å™¨
        link_manager = LinkManager(
            knowledge_base_path=settings.knowledge_base_path
        )
        logger.info("é“¾æ¥ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–çŸ¥è¯†ç¼–æ’å™¨ - ä½œä¸ºå¤‡ç”¨
        progress_callback = SimpleProgressCallback()
        
        orchestrator = KnowledgeOrchestrator(
            knowledge_base_path=settings.knowledge_base_path,
            progress_callback=progress_callback
        )
        logger.info("çŸ¥è¯†ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æ–‡ä»¶ç›‘æ§å™¨
        def file_change_callback(change_info):
            """æ–‡ä»¶å˜åŒ–å›è°ƒå‡½æ•°"""
            logger.info(f"æ–‡ä»¶å˜åŒ–é€šçŸ¥: {change_info}")
            # å¯ä»¥é€šè¿‡WebSocketé€šçŸ¥å‰ç«¯
            if active_websocket_connections:
                asyncio.create_task(broadcast_progress(change_info))
        
        file_watcher = create_file_watcher(
            knowledge_base_path=settings.knowledge_base_path,
            link_manager=link_manager,
            callback=file_change_callback
        )
        file_watcher.start()
        logger.info("æ–‡ä»¶ç›‘æ§å™¨å¯åŠ¨å®Œæˆ")
        
        logger.info("Knowledge Agent API æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
        
    except Exception as e:
        logger.error(f"æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        raise

# å…³é—­æ—¶æ¸…ç†
@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº"""
    global file_watcher
    
    logger.info("æ­£åœ¨å…³é—­ Knowledge Agent API æœåŠ¡å™¨...")
    
    if file_watcher:
        file_watcher.stop()
        logger.info("æ–‡ä»¶ç›‘æ§å™¨å·²åœæ­¢")
    
    # å…³é—­æ‰€æœ‰WebSocketè¿æ¥
    for websocket in active_websocket_connections.copy():
        try:
            await websocket.close()
        except:
            pass
    active_websocket_connections.clear()
    
    logger.info("Knowledge Agent API æœåŠ¡å™¨å·²å…³é—­")

# API è·¯ç”±

@app.get("/", tags=["General"])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Knowledge Agent API",
        "version": "1.0.0",
        "docs": "/docs",
        "status": "running"
    }

@app.get("/health", tags=["General"])
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "simple_processor": simple_processor is not None,
            "orchestrator": orchestrator is not None,
            "vector_db": vector_db is not None,
            "link_manager": link_manager is not None,
            "file_watcher": file_watcher is not None and file_watcher.is_running if file_watcher else False
        }
    }

@app.get("/file-watcher/status", tags=["General"])
async def get_file_watcher_status():
    """è·å–æ–‡ä»¶ç›‘æ§å™¨çŠ¶æ€"""
    if not file_watcher:
        return {
            "enabled": False,
            "status": "æœªå¯ç”¨",
            "message": "æ–‡ä»¶ç›‘æ§å™¨æœªåˆå§‹åŒ–"
        }
    
    status = file_watcher.get_status()
    return {
        "enabled": True,
        "status": status,
        "message": "æ–‡ä»¶ç›‘æ§å™¨è¿è¡Œæ­£å¸¸" if status['is_running'] else "æ–‡ä»¶ç›‘æ§å™¨å·²åœæ­¢"
    }

@app.get("/stats", response_model=StatsResponse, tags=["General"])
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è·å–å‘é‡æ•°æ®åº“ç»Ÿè®¡
        db_stats = vector_db.get_collection_stats() if vector_db else {}
        
        # è·å–é“¾æ¥ç®¡ç†å™¨ç»Ÿè®¡
        link_stats = link_manager.get_stats() if link_manager else {}
        
        return StatsResponse(
            documents=db_stats.get("documents", 0),
            concepts=db_stats.get("concepts", 0),
            links=link_stats.get("total_links", 0),
            last_updated=datetime.now().isoformat()
        )
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/rescan", tags=["General"])
async def rescan_knowledge_base():
    """é‡æ–°æ‰«æçŸ¥è¯†åº“"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        # é‡æ–°æ‰«æçŸ¥è¯†åº“
        stats = await asyncio.get_event_loop().run_in_executor(
            None, link_manager.scan_knowledge_base_simple
        )
        
        return {
            "success": True,
            "message": "çŸ¥è¯†åº“é‡æ–°æ‰«æå®Œæˆ",
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"é‡æ–°æ‰«æçŸ¥è¯†åº“å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/process", response_model=ProcessingResponse, tags=["Processing"])
async def process_content(request: ProcessingRequest):
    """å¤„ç†å†…å®¹"""
    try:
        if not simple_processor:
            raise HTTPException(status_code=500, detail="ç®€åŒ–å¤„ç†å™¨æœªåˆå§‹åŒ–")
        
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†å†…å®¹ï¼Œé•¿åº¦: {len(request.content)} å­—ç¬¦")
        
        # ä½¿ç”¨AIç¼–æ’å¤„ç†å™¨ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        result = await simple_processor.process_content(
            content=request.content,
            content_type=request.type,
            metadata=request.metadata,
            options={
                "enable_linking": request.options.enableLinking,
                "enable_vector_db": request.options.enable_vector_db,
                "force_structure": request.options.force_structure,
                "batch_mode": False,
                "enable_ai_orchestration": True  # å¯ç”¨AIç¼–æ’
            }
        )
        
        logger.info(f"âœ… å¤„ç†å®Œæˆ: {'æˆåŠŸ' if result.get('success') else 'å¤±è´¥'}")
        
        return ProcessingResponse(
            success=result.get("success", False),
            result=result.get("result"),
            output_file="",  # ç®€åŒ–å¤„ç†å™¨æš‚ä¸ä¿å­˜æ–‡ä»¶
            doc_id=result.get("doc_id"),
            statistics=result.get("result", {}).get("statistics", {}),
            errors=[result.get("error")] if result.get("error") else [],
            message="å¤„ç†å®Œæˆ"
        )
        
    except Exception as e:
        logger.error(f"å¤„ç†å†…å®¹å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload", response_model=ProcessingResponse, tags=["Processing"])
async def upload_file(file: UploadFile = File(...)):
    """ä¸Šä¼ æ–‡ä»¶å¤„ç†"""
    try:
        if not orchestrator:
            raise HTTPException(status_code=500, detail="ç¼–æ’å™¨æœªåˆå§‹åŒ–")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_types = ['.md', '.txt', '.doc', '.docx']
        file_extension = '.' + file.filename.split('.')[-1].lower()
        
        if file_extension not in allowed_types:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}. æ”¯æŒçš„ç±»å‹: {', '.join(allowed_types)}"
            )
        
        # è§£ç æ–‡ä»¶å†…å®¹
        try:
            text_content = content.decode('utf-8')
        except UnicodeDecodeError:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶ç¼–ç ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨ UTF-8 ç¼–ç ")
        
        # æ„å»ºå¤„ç†å‚æ•°
        input_data = {
            "content": text_content,
            "type": "text",
            "metadata": {
                "source": file.filename,
                "upload_time": datetime.now().isoformat()
            },
            "operation": "create",
            "options": {
                "enable_linking": True,
                "enable_vector_db": True,
                "force_structure": False,
                "batch_mode": False
            }
        }
        
        # æ‰§è¡Œå¤„ç†
        result = await asyncio.get_event_loop().run_in_executor(
            None, orchestrator.process, input_data
        )
        
        return ProcessingResponse(
            success=result.get("success", False),
            result=result.get("result"),
            output_file=result.get("output_file"),
            doc_id=result.get("doc_id"),
            statistics=result.get("statistics"),
            errors=result.get("errors", []),
            message=f"æ–‡ä»¶ {file.filename} å¤„ç†å®Œæˆ"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search/concepts", response_model=ConceptSearchResponse, tags=["Search"])
async def search_concepts(request: ConceptSearchRequest):
    """æœç´¢æ¦‚å¿µ"""
    try:
        if not vector_db:
            raise HTTPException(status_code=500, detail="å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
        
        results = vector_db.search_related_concepts(
            query=request.query,
            n_results=request.limit,
            threshold=request.threshold
        )
        
        return ConceptSearchResponse(
            concepts=results,
            total=len(results),
            query=request.query
        )
        
    except Exception as e:
        logger.error(f"æœç´¢æ¦‚å¿µå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search/documents", response_model=DocumentSearchResponse, tags=["Search"])
async def search_documents(request: DocumentSearchRequest):
    """æœç´¢æ–‡æ¡£"""
    try:
        if not vector_db:
            raise HTTPException(status_code=500, detail="å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
        
        results = vector_db.search_similar_documents(
            query=request.query,
            n_results=request.limit,
            threshold=request.threshold
        )
        
        return DocumentSearchResponse(
            documents=results,
            total=len(results),
            query=request.query
        )
        
    except Exception as e:
        logger.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/discover/links", response_model=LinkDiscoveryResponse, tags=["Links"])
async def discover_links(request: LinkDiscoveryRequest):
    """å‘ç°é“¾æ¥"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        links = link_manager.discover_links_for_document(
            doc_id=request.doc_id,
            threshold=request.threshold
        )
        
        return LinkDiscoveryResponse(
            links=links,
            total=len(links),
            doc_id=request.doc_id
        )
        
    except Exception as e:
        logger.error(f"å‘ç°é“¾æ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/concepts", tags=["Concepts"])
async def list_concepts(limit: int = 100, offset: int = 0):
    """åˆ—å‡ºæ‰€æœ‰æ¦‚å¿µ"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        concepts = link_manager.get_all_concepts(limit=limit, offset=offset)
        
        return {
            "concepts": concepts,
            "total": len(concepts),
            "limit": limit,
            "offset": offset
        }
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ¦‚å¿µå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/concepts/{concept_name}", tags=["Concepts"])
async def get_concept(concept_name: str):
    """è·å–ç‰¹å®šæ¦‚å¿µçš„è¯¦ç»†ä¿¡æ¯"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        concept_info = link_manager.get_concept_info(concept_name)
        
        if not concept_info:
            raise HTTPException(status_code=404, detail=f"æ¦‚å¿µ '{concept_name}' ä¸å­˜åœ¨")
        
        return concept_info
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ¦‚å¿µä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/concept-graph", response_model=ConceptGraphResponse, tags=["Concepts"])
async def get_concept_graph(max_concepts: int = 100, include_documents: bool = False):
    """è·å–æ¦‚å¿µå›¾è°±æ•°æ®"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        # åˆ›å»ºæ¦‚å¿µå›¾ç”Ÿæˆå™¨
        graph_generator = ConceptGraphGenerator(link_manager)
        
        # ç”Ÿæˆå›¾è°±æ•°æ®
        graph_data = await asyncio.get_event_loop().run_in_executor(
            None, graph_generator.generate_graph_data, max_concepts
        )
        
        # è½¬æ¢æ•°æ®æ ¼å¼ä»¥ç¬¦åˆå‰ç«¯é¢„æœŸ
        nodes = []
        for node in graph_data['nodes']:
            nodes.append({
                'id': str(node['id']),
                'label': node['label'],
                'type': 'concept',
                'size': node['size'],
                'color': node['color'],
                'metadata': {
                    'referenceCount': node.get('size', 10) - 10,  # ä»sizeåæ¨å¼•ç”¨æ¬¡æ•°
                    'hasDocument': node['color'] == '#0066cc',  # è“è‰²è¡¨ç¤ºæœ‰æ–‡æ¡£
                    'category': 'concept'
                }
            })
        
        # è½¬æ¢é“¾æ¥æ•°æ®
        links = []
        for link in graph_data['links']:
            links.append({
                'source': str(link['source']),
                'target': str(link['target']),
                'weight': link['weight'],
                'type': 'concept-link'
            })
        
        return ConceptGraphResponse(
            nodes=nodes,
            links=links,
            total_concepts=len(nodes),
            total_links=len(links)
        )
        
    except Exception as e:
        logger.error(f"è·å–æ¦‚å¿µå›¾è°±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/documents", tags=["Documents"])
async def list_documents(limit: int = 100, offset: int = 0):
    """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        documents = link_manager.get_all_documents(limit=limit, offset=offset)
        
        return {
            "documents": documents,
            "total": len(documents),
            "limit": limit,
            "offset": offset
        }
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ–‡æ¡£å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/documents/{doc_id}", tags=["Documents"])
async def get_document(doc_id: str):
    """è·å–ç‰¹å®šæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        doc_info = link_manager.get_document_info(doc_id)
        
        if not doc_info:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ '{doc_id}' ä¸å­˜åœ¨")
        
        return doc_info
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/documents/{doc_id}", tags=["Documents"])
async def delete_document(doc_id: str):
    """åˆ é™¤æ–‡æ¡£"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        # è·å–æ–‡æ¡£ä¿¡æ¯
        doc_info = link_manager.get_document_info(doc_id)
        if not doc_info:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ '{doc_id}' ä¸å­˜åœ¨")
        
        doc_path = doc_info.get('doc_path')
        if not doc_path:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£è·¯å¾„ä¸å­˜åœ¨")
        
        # åˆ é™¤ç‰©ç†æ–‡ä»¶
        resolved_path = link_manager._resolve_document_path(doc_path)
        try:
            if os.path.exists(resolved_path):
                os.remove(resolved_path)
                logger.info(f"åˆ é™¤ç‰©ç†æ–‡ä»¶: {resolved_path}")
        except Exception as e:
            logger.warning(f"åˆ é™¤ç‰©ç†æ–‡ä»¶å¤±è´¥: {e}")
            # å³ä½¿æ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œä¹Ÿç»§ç»­åˆ é™¤æ•°æ®åº“è®°å½•
        
        # ä»æ•°æ®åº“ä¸­åˆ é™¤æ–‡æ¡£è®°å½•
        success = link_manager.remove_document(doc_path)
        
        if success:
            return {
                "success": True,
                "message": f"æ–‡æ¡£ '{doc_info.get('title', doc_id)}' åˆ é™¤æˆåŠŸ",
                "doc_id": doc_id
            }
        else:
            raise HTTPException(status_code=500, detail="åˆ é™¤æ–‡æ¡£è®°å½•å¤±è´¥")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/documents/{doc_id}/content", tags=["Documents"])
async def get_document_content(doc_id: str):
    """è·å–æ–‡æ¡£å†…å®¹"""
    try:
        if not link_manager:
            raise HTTPException(status_code=500, detail="é“¾æ¥ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        doc_info = link_manager.get_document_info(doc_id)
        
        if not doc_info:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ '{doc_id}' ä¸å­˜åœ¨")
        
        doc_path = doc_info.get('doc_path')
        if not doc_path:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£è·¯å¾„ä¸å­˜åœ¨")
        
        # å¤„ç†è·¯å¾„è½¬æ¢ - å°†æ—§è·¯å¾„è½¬æ¢ä¸ºæ–°è·¯å¾„
        resolved_path = link_manager._resolve_document_path(doc_path)
        
        try:
            with open(resolved_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return {"content": content}
        except FileNotFoundError:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨: {resolved_path}")
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"è¯»å–æ–‡æ¡£å¤±è´¥: {str(e)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# WebSocket è·¯ç”±
@app.websocket("/ws/progress")
async def websocket_progress(websocket: WebSocket):
    """WebSocket è¿›åº¦æ¨é€"""
    await websocket.accept()
    logger.info(f"æ–°çš„WebSocketè¿æ¥å·²å»ºç«‹ï¼Œå½“å‰è¿æ¥æ•°: {len(active_websocket_connections) + 1}")
    
    # æ·»åŠ åˆ°æ´»è·ƒè¿æ¥é›†åˆ
    active_websocket_connections.add(websocket)
    
    try:
        # å‘é€è¿æ¥ç¡®è®¤æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "type": "connection_confirmed",
            "message": "WebSocketè¿æ¥å·²å»ºç«‹",
            "timestamp": time.time()
        }))
        
        # ä¿æŒè¿æ¥ç›´åˆ°æ–­å¼€
        while True:
            try:
                message = await websocket.receive_text()
                # å¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯ï¼ˆå¦‚ping/pongï¼‰
                try:
                    data = json.loads(message)
                    if data.get("type") == "ping":
                        await websocket.send_text(json.dumps({
                            "type": "pong",
                            "timestamp": time.time()
                        }))
                except json.JSONDecodeError:
                    pass
            except WebSocketDisconnect:
                logger.info("WebSocketè¿æ¥æ–­å¼€")
                break
                
    except Exception as e:
        logger.error(f"WebSocket é”™è¯¯: {str(e)}")
    finally:
        # ä»æ´»è·ƒè¿æ¥ä¸­ç§»é™¤
        active_websocket_connections.discard(websocket)
        logger.info(f"WebSocketè¿æ¥å·²ç§»é™¤ï¼Œå½“å‰è¿æ¥æ•°: {len(active_websocket_connections)}")

# ä¸»å‡½æ•°
def main():
    """å¯åŠ¨ API æœåŠ¡å™¨"""
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )

if __name__ == "__main__":
    main()