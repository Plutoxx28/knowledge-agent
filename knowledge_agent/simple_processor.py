#!/usr/bin/env python3
"""
ç®€åŒ–çš„çŸ¥è¯†å¤„ç†å™¨ - é‡æ–°å®ç°ä¸€ä¸ªå¯å·¥ä½œçš„ç‰ˆæœ¬
"""
import asyncio
import json
import logging
import time
import uuid
from typing import Dict, Any, List, Optional, Callable
from openai import OpenAI
from config import settings

logger = logging.getLogger(__name__)

class SimpleProgressTracker:
    """ç®€åŒ–çš„è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, websocket_broadcast_func: Optional[Callable] = None):
        self.websocket_broadcast = websocket_broadcast_func
        self.task_id = str(uuid.uuid4())
        
    async def update_progress(self, stage: str, message: str, progress_percent: int, workers: List[str] = None):
        """æ›´æ–°è¿›åº¦"""
        progress_data = {
            "task_id": self.task_id,
            "stage": stage,
            "current_step": message,
            "progress_percent": progress_percent,
            "workers": workers or [],
            "timestamp": time.time()
        }
        
        logger.info(f"ğŸ¯ è¿›åº¦æ›´æ–°: {stage} - {message} ({progress_percent}%)")
        
        if self.websocket_broadcast:
            try:
                await self.websocket_broadcast(progress_data)
                logger.info(f"âœ… WebSocketè¿›åº¦å¹¿æ’­æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ WebSocketè¿›åº¦å¹¿æ’­å¤±è´¥: {e}")
        else:
            logger.info("ğŸ“¡ æ²¡æœ‰WebSocketå¹¿æ’­å‡½æ•°ï¼Œè·³è¿‡è¿›åº¦å¹¿æ’­")

class SimpleKnowledgeProcessor:
    """ç®€åŒ–çš„çŸ¥è¯†å¤„ç†å™¨"""
    
    def __init__(self, websocket_broadcast_func: Optional[Callable] = None):
        self.websocket_broadcast = websocket_broadcast_func
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        try:
            self.ai_client = OpenAI(
                base_url=settings.openrouter_base_url,
                api_key=settings.openrouter_api_key,
                default_headers={
                    "HTTP-Referer": "https://knowledge-agent.local",
                    "X-Title": "Knowledge Agent System",
                }
            )
            logger.info(f"AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {settings.model_name}")
            logger.info(f"API Keyå‰ç¼€: {settings.openrouter_api_key[:20]}...")
            logger.info(f"Base URL: {settings.openrouter_base_url}")
        except Exception as e:
            logger.error(f"AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ai_client = None
        
        logger.info("ç®€åŒ–çŸ¥è¯†å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def process_content(self, content: str, content_type: str = "text", 
                            metadata: Dict[str, Any] = None, 
                            options: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¤„ç†å†…å®¹çš„ä¸»è¦æ–¹æ³•"""
        
        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        tracker = SimpleProgressTracker(self.websocket_broadcast)
        
        try:
            # é˜¶æ®µ1: å¼€å§‹åˆ†æ (0-20%)
            await tracker.update_progress("analyzing", "ğŸ¤– AIåˆ†æå†…å®¹ä¸­...", 10, ["AIåˆ†æå™¨"])
            
            # ä½¿ç”¨AIåˆ†æå†…å®¹
            analysis = await self._ai_analyze_content(content)
            await tracker.update_progress("analyzing", "âœ… AIåˆ†æå®Œæˆ", 20)
            
            # é˜¶æ®µ2: æ¦‚å¿µæå– (20-50%)
            await tracker.update_progress("worker_processing", "ğŸ§  AIæ¦‚å¿µæå–ä¸­...", 30, ["æ¦‚å¿µæå–å™¨"])
            
            concepts = await self._ai_extract_concepts(content)
            await tracker.update_progress("worker_processing", "âœ… æ¦‚å¿µæå–å®Œæˆ", 50)
            
            # é˜¶æ®µ3: ç»“æ„åŒ–å¤„ç† (50-80%)
            await tracker.update_progress("worker_processing", "ğŸ—ï¸ ç»“æ„åŒ–æ„å»ºä¸­...", 60, ["ç»“æ„æ„å»ºå™¨"])
            
            structured_content = await self._ai_structure_content(content, concepts, analysis)
            await tracker.update_progress("worker_processing", "âœ… ç»“æ„åŒ–å®Œæˆ", 80)
            
            # é˜¶æ®µ4: å®Œæˆå¤„ç† (80-100%)
            await tracker.update_progress("finalizing", "ğŸ’¾ ä¿å­˜å¤„ç†ç»“æœ...", 90, ["æ–‡ä»¶ç®¡ç†å™¨"])
            
            # æ£€æŸ¥AIå¤„ç†æ˜¯å¦æˆåŠŸ
            ai_success = not (analysis.get('error') or any('error' in str(c) for c in concepts))
            processing_method = "AIå¢å¼º" if ai_success else "åŸºç¡€æ¨¡æ¿"
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            result = {
                "content": structured_content,
                "concepts": concepts,
                "analysis": analysis,
                "metadata": metadata or {},
                "statistics": {
                    "original_length": len(content),
                    "processed_length": len(structured_content),
                    "concept_count": len(concepts),
                    "ai_enhanced": ai_success,
                    "processing_method": processing_method,
                    "ai_calls_successful": ai_success
                }
            }
            
            await tracker.update_progress("completed", "ğŸ‰ å¤„ç†å®Œæˆï¼", 100)
            
            return {
                "success": True,
                "result": result,
                "doc_id": tracker.task_id,
                "task_id": tracker.task_id
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {e}")
            await tracker.update_progress("error", f"âŒ å¤„ç†å¤±è´¥: {str(e)}", 0)
            return {
                "success": False,
                "error": str(e),
                "task_id": tracker.task_id
            }
    
    async def _ai_analyze_content(self, content: str) -> Dict[str, Any]:
        """AIåˆ†æå†…å®¹"""
        if not self.ai_client:
            logger.error("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨fallbackåˆ†æ")
            return {
                "main_topic": "å†…å®¹åˆ†æ",
                "complexity": "medium",
                "content_type": "general",
                "key_themes": [],
                "error": "AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
            }
            
        try:
            logger.info(f"ğŸ¤– å¼€å§‹AIå†…å®¹åˆ†æ... ä½¿ç”¨æ¨¡å‹: {settings.model_name}")
            
            response = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: self.ai_client.chat.completions.create(
                    model=settings.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç»™å®šå†…å®¹çš„ä¸»é¢˜ã€å¤æ‚åº¦å’Œç»“æ„ã€‚"
                        },
                        {
                            "role": "user",
                            "content": f"""è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š

{content[:1500]}

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
  "main_topic": "ä¸»è¦è¯é¢˜",
  "complexity": "simple|medium|complex",
  "content_type": "technical|educational|general",
  "key_themes": ["ä¸»é¢˜1", "ä¸»é¢˜2"]
}}"""
                        }
                    ],
                    max_tokens=500,
                    temperature=0.3
                )
            )
            
            ai_response = response.choices[0].message.content
            logger.info(f"âœ… AIåˆ†æå“åº”: {ai_response[:200]}...")
            
            try:
                return json.loads(ai_response)
            except json.JSONDecodeError:
                return {
                    "main_topic": "æœªçŸ¥ä¸»é¢˜",
                    "complexity": "medium",
                    "content_type": "general",
                    "key_themes": [],
                    "ai_raw_response": ai_response
                }
                
        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            return {
                "main_topic": "åˆ†æå¤±è´¥",
                "complexity": "medium",
                "content_type": "general",
                "key_themes": [],
                "error": str(e)
            }
    
    async def _ai_extract_concepts(self, content: str) -> List[Dict[str, Any]]:
        """AIæ¦‚å¿µæå–"""
        if not self.ai_client:
            logger.error("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨fallbackæ¦‚å¿µæå–")
            return self._fallback_concept_extraction(content)
            
        try:
            logger.info(f"ğŸ§  å¼€å§‹AIæ¦‚å¿µæå–... ä½¿ç”¨æ¨¡å‹: {settings.model_name}")
            
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.ai_client.chat.completions.create(
                    model=settings.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¦‚å¿µæå–ä¸“å®¶ã€‚è¯·ä»å†…å®¹ä¸­æå–æ ¸å¿ƒæ¦‚å¿µå’Œé‡è¦æœ¯è¯­ã€‚"
                        },
                        {
                            "role": "user",
                            "content": f"""è¯·ä»ä»¥ä¸‹å†…å®¹ä¸­æå–æ ¸å¿ƒæ¦‚å¿µï¼š

{content[:1500]}

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›æ¦‚å¿µåˆ—è¡¨ï¼š
[
  {{"term": "æ¦‚å¿µåç§°", "definition": "æ¦‚å¿µå®šä¹‰", "type": "æ¦‚å¿µç±»å‹", "confidence": 0.9}},
  {{"term": "æœ¯è¯­åç§°", "definition": "æœ¯è¯­è§£é‡Š", "type": "technical_term", "confidence": 0.8}}
]"""
                        }
                    ],
                    max_tokens=800,
                    temperature=0.3
                )
            )
            
            ai_response = response.choices[0].message.content
            logger.info(f"âœ… AIæ¦‚å¿µæå–å“åº”: {ai_response[:200]}...")
            
            try:
                # æ¸…ç†å“åº”ä¸­çš„markdownæ ‡è®°
                clean_response = ai_response.strip()
                if clean_response.startswith('```json'):
                    clean_response = clean_response[7:]
                if clean_response.endswith('```'):
                    clean_response = clean_response[:-3]
                clean_response = clean_response.strip()
                
                concepts = json.loads(clean_response)
                # æ·»åŠ AIæ ‡è®°
                for concept in concepts:
                    concept['source'] = 'ai_enhanced'
                    concept['final_score'] = concept.get('confidence', 0.7)
                
                logger.info(f"âœ… AIæˆåŠŸæå–äº† {len(concepts)} ä¸ªæ¦‚å¿µ")
                return concepts
                
            except json.JSONDecodeError as e:
                logger.warning(f"AIæ¦‚å¿µæå–JSONè§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                return self._fallback_concept_extraction(content)
                
        except Exception as e:
            logger.error(f"AIæ¦‚å¿µæå–å¤±è´¥: {e}")
            return self._fallback_concept_extraction(content)
    
    def _fallback_concept_extraction(self, content: str) -> List[Dict[str, Any]]:
        """å¤‡ç”¨æ¦‚å¿µæå–æ–¹æ³•"""
        import re
        concepts = []
        
        # ç®€å•çš„å…³é”®è¯æå–
        patterns = [
            (r'\b([A-Z]{2,})\b', 'acronym'),
            (r'([ä¸€-é¾Ÿ]{2,8})', 'chinese_term'),
            (r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\b', 'proper_noun'),
        ]
        
        for pattern, term_type in patterns:
            matches = re.findall(pattern, content)
            for match in matches[:5]:  # é™åˆ¶æ•°é‡
                concepts.append({
                    'term': match,
                    'definition': '',
                    'type': term_type,
                    'confidence': 0.6,
                    'source': 'fallback_extraction',
                    'final_score': 0.6
                })
        
        return concepts[:10]  # æœ€å¤š10ä¸ªæ¦‚å¿µ
    
    async def _ai_structure_content(self, content: str, concepts: List[Dict], 
                                  analysis: Dict[str, Any]) -> str:
        """AIç»“æ„åŒ–å†…å®¹"""
        if not self.ai_client:
            logger.error("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨fallbackç»“æ„åŒ–")
            return self._create_fallback_structure(content, concepts, analysis)
            
        try:
            logger.info(f"ğŸ—ï¸ å¼€å§‹AIç»“æ„åŒ–... ä½¿ç”¨æ¨¡å‹: {settings.model_name}")
            
            concept_names = [c['term'] for c in concepts[:10]]  # æœ€å¤š10ä¸ªæ¦‚å¿µ
            
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.ai_client.chat.completions.create(
                    model=settings.model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†æ•´ç†ä¸“å®¶ã€‚è¯·å°†å†…å®¹é‡æ–°ç»„ç»‡ä¸ºç»“æ„åŒ–çš„Markdownæ ¼å¼ã€‚"
                        },
                        {
                            "role": "user",
                            "content": f"""è¯·å°†ä»¥ä¸‹å†…å®¹é‡æ–°æ•´ç†ä¸ºç»“æ„åŒ–çš„Markdownæ ¼å¼ï¼š

åŸå§‹å†…å®¹ï¼š
{content}

ä¸»è¦æ¦‚å¿µï¼š{', '.join(concept_names)}

è¦æ±‚ï¼š
1. ä½¿ç”¨æ¸…æ™°çš„Markdownæ ‡é¢˜ç»“æ„
2. ä¸ºé‡è¦æ¦‚å¿µæ·»åŠ åŒé“¾æ ¼å¼ï¼š[[æ¦‚å¿µå]]
3. ä¿æŒåŸæ„ä¸å˜ï¼Œä½†ç»„ç»‡æ›´æ¸…æ™°
4. æ·»åŠ æ ¸å¿ƒæ¦‚å¿µåˆ—è¡¨

è¯·è¿”å›é‡æ–°æ•´ç†åçš„Markdownå†…å®¹ã€‚"""
                        }
                    ],
                    max_tokens=1500,
                    temperature=0.3
                )
            )
            
            structured = response.choices[0].message.content
            logger.info(f"âœ… AIç»“æ„åŒ–å®Œæˆï¼Œé•¿åº¦: {len(structured)}")
            
            return structured
            
        except Exception as e:
            logger.error(f"AIç»“æ„åŒ–å¤±è´¥: {e}")
            # ä½¿ç”¨fallbackæ–¹æ³•
            return self._create_fallback_structure(content, concepts, analysis)
    
    def _create_fallback_structure(self, content: str, concepts: List[Dict], analysis: Dict[str, Any]) -> str:
        """åˆ›å»ºfallbackç»“æ„åŒ–å†…å®¹"""
        main_topic = analysis.get('main_topic', 'çŸ¥è¯†æ•´ç†')
        if main_topic == "æœªçŸ¥ä¸»é¢˜" or main_topic == "åˆ†æå¤±è´¥":
            # å°è¯•ä»å†…å®¹ä¸­æå–æ ‡é¢˜
            lines = content.strip().split('\n')
            for line in lines[:5]:
                line = line.strip()
                if line.startswith('#'):
                    main_topic = line.lstrip('#').strip()
                    break
                elif len(line) > 5 and len(line) < 100:
                    main_topic = line
                    break
            else:
                main_topic = "çŸ¥è¯†æ•´ç†"
        
        # æ„å»ºæ›´å¥½çš„fallbackå†…å®¹
        structured_parts = [f"# {main_topic}"]
        
        # æ·»åŠ æ¦‚å¿µéƒ¨åˆ†
        if concepts and len(concepts) > 0:
            structured_parts.append("\n## æ ¸å¿ƒæ¦‚å¿µ\n")
            valid_concepts = [c for c in concepts[:8] if c.get('term') and len(c['term'].strip()) > 1]
            if valid_concepts:
                for concept in valid_concepts:
                    term = concept['term'].strip()
                    definition = concept.get('definition', '').strip()
                    if definition:
                        structured_parts.append(f"- **[[{term}]]**: {definition}")
                    else:
                        structured_parts.append(f"- **[[{term}]]**")
            else:
                structured_parts.append("- æš‚æ— æå–åˆ°æœ‰æ•ˆæ¦‚å¿µ")
        
        # æ·»åŠ å†…å®¹éƒ¨åˆ†
        structured_parts.append(f"\n## è¯¦ç»†å†…å®¹\n\n{content}")
        
        # æ·»åŠ å¤„ç†ä¿¡æ¯
        complexity = analysis.get('complexity', 'medium')
        content_type = analysis.get('content_type', 'general')
        structured_parts.append(f"\n---\n*æœ¬æ–‡æ¡£å¤æ‚åº¦: {complexity} | å†…å®¹ç±»å‹: {content_type} | å¤„ç†æ–¹å¼: åŸºç¡€æ¨¡æ¿*")
        
        return '\n'.join(structured_parts)