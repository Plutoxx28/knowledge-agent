预训练（Pre-training）
从零开始打基础

模型参数随机初始化，完全空白状态
用海量无标注文本数据进行训练
目标：学会语言的基本规律和世界知识
就像让一个婴儿通过大量阅读学会语言和常识

继续预训练（Continued Pre-training）
扩充知识库

基于已有预训练模型，用新的文本数据继续训练
目标：补充特定领域知识或更新信息
模型还是在"学知识"，但更有针对性
就像让一个有基础知识的人专门学习某个专业领域

后训练（Post-training）
成为一个好助手

使用指令-回答对等结构化数据进行训练
包括监督微调（SFT）和人类反馈强化学习（RLHF）
目标：学会理解人类意图，生成有用、安全的回答
就像教一个知识丰富的人如何做老师或顾问

整个流程：空白大脑 → 博学的人 → 专业领域专家 → 优秀的AI助手
三个阶段各有分工：预训练打地基，继续预训练扩展专业知识，后训练学会服务人类。缺了任何一个环节，都不能成为我们现在使用的这种既博学又好用的AI助手。