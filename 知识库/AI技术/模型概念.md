# 预训练（Pre-training）
从零开始打基础

模型参数随机初始化，完全空白状态
用海量无标注文本数据进行训练
目标：学会语言的基本规律和世界知识
就像让一个婴儿通过大量阅读学会语言和常识

继续预训练（Continued Pre-training）
扩充知识库

基于已有预训练模型，用新的文本数据继续训练
目标：补充特定领域知识或更新信息
模型还是在"学知识"，但更有针对性
就像让一个有基础知识的人专门学习某个专业领域

后训练（Post-training）
成为一个好助手

使用指令-回答对等结构化数据进行训练
包括监督微调（SFT）和人类反馈强化学习（RLHF）
目标：学会理解人类意图，生成有用、安全的回答
就像教一个知识丰富的人如何做老师或顾问

整个流程：空白大脑 → 博学的人 → 专业领域专家 → 优秀的AI助手
三个阶段各有分工：预训练打地基，继续预训练扩展专业知识，后训练学会服务人类。缺了任何一个环节，都不能成为我们现在使用的这种既博学又好用的AI助手。

## 继续预训练 vs 微调的详细区别

### 核心区别
- **继续预训练**：教模型"学知识"，让通用模型学习特定领域的语言、术语和事实，使其成为该领域的知识专家。过程是无监督的。
- **微调**：教模型"学技能"，让已具备相关知识的模型学会执行特定任务。过程是有监督的。

### 详细对比

| 特征 | 继续预训练 | 微调 |
|------|-----------|------|
| **目标** | 知识注入/领域适应，学习特定领域的语言风格、专业术语和背景知识 | 任务适应，学会完成具体的、有明确输入输出格式的任务 |
| **数据** | 大量无标签的领域文本（如医学论文、法律文书、公司内部文档） | 少量有标签的任务特定数据集（如问题-答案对、指令-输出对） |
| **任务类型** | 与原始预训练任务相同的自监督学习（掩码语言模型或因果语言模型） | 新的下游任务的监督学习（分类、问答、摘要、指令遵循等） |
| **模型修改** | 通常不改变模型结构，只更新权重，可能扩展词汇表 | 通常添加任务头，在模型主体上加新的网络层用于输出任务结果 |
| **结果** | 领域专属的基础模型，更懂特定领域但不会直接做具体任务 | 任务专属的专家模型，能很好地完成特定任务 |

### 模型生命周期的不同路径

**标准路径**（最常见）：
原始预训练 → 微调 → 部署应用

适用场景：任务所涉及的领域知识和语言风格在原始预训练数据中已被充分覆盖。

**专业路径**（领域增强）：
原始预训练 → 继续预训练 → 微调 → 部署应用

适用场景：任务在非常专业或独特的领域（法律、医疗、金融、公司内部文档），通用模型对这些领域理解不足。

### 路径选择策略

**只需要微调的情况**：
- 通用闲聊、电影评论情感分析等任务
- 所需知识在通用基础模型的训练数据中已很常见

**需要继续预训练+微调的情况**：
- 法律领域：需要理解复杂的法律条文和案例
- 金融领域：需要理解财报、市场分析报告  
- 特定企业：需要理解公司内部术语、项目代号和知识库

### 关系总结

1. **预训练**：模型的起点，构建通用知识基础
2. **微调**：模型适应具体任务的终点，教模型如何行动
3. **继续预训练**：可选的桥梁，当通用模型和专业任务间知识差距过大时，搭建知识缓冲区

微调可以直接跟在原始预训练之后，也可以跟在继续预训练之后。选择哪条路径取决于任务、数据和对模型性能的要求。

---

## 知识链式关系

### 核心概念链
- [[预训练]] → [[继续预训练]] → [[微调]] → [[后训练]]
- [[无监督学习]] → [[自监督学习]] → [[监督学习]] → [[强化学习]]
- [[通用模型]] → [[领域模型]] → [[任务模型]] → [[应用模型]]

### 数据类型链
- [[海量无标注文本]] → [[领域专业文本]] → [[标注任务数据]] → [[人类反馈数据]]

### 训练目标链
- [[语言建模]] → [[领域适应]] → [[任务适应]] → [[人类对齐]]

### 模型能力链
- [[语言理解]] → [[专业知识]] → [[任务执行]] → [[安全输出]]

### 应用场景链
- [[通用对话]] → [[专业咨询]] → [[具体任务]] → [[部署应用]]

### 技术方法链
- [[掩码语言模型]] → [[因果语言模型]] → [[任务头]] → [[强化学习算法]]
- [[MLM]] → [[CLM]] → [[分类头]] → [[RLHF]]

### 评估指标链
- [[困惑度]] → [[领域准确率]] → [[任务准确率]] → [[人类偏好分数]]

### 资源需求链
- [[大规模计算]] → [[中等计算]] → [[小规模计算]] → [[推理优化]]

### 相关概念
- [[词汇表扩展]] - 在继续预训练中可能需要
- [[知识蒸馏]] - 模型压缩技术
- [[参数高效微调]] - PEFT方法如LoRA
- [[上下文学习]] - Few-shot learning
- [[指令遵循]] - Instruction following
- [[对话能力]] - Conversational AI
- [[多模态训练]] - 图文等多模态数据